{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features are unspecified. Defaut is set to = 272.\n",
      "Num GPUs Available:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ash Gao\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:143: FutureWarning: The sklearn.datasets.samples_generator module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.datasets. Anything that cannot be imported from sklearn.datasets is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.constraints import maxnorm\n",
    "from keras.layers import Convolution1D, Dense, MaxPooling1D, Flatten, Add, Dropout, Input, Activation\n",
    "from keras.layers import TimeDistributed, Bidirectional, LSTM, LeakyReLU\n",
    "from keras.models import Sequential\n",
    "from keras import optimizers, regularizers\n",
    "from keras.utils import np_utils, to_categorical\n",
    "from keras.models import Model, load_model, Sequential\n",
    "from keras.regularizers import l2\n",
    "\n",
    "import keras\n",
    "\n",
    "from IPython.display import clear_output\n",
    "from tensorflow.python.client import device_lib\n",
    "from tensorflow.python.keras import backend\n",
    "import tensorflow as tf\n",
    "\n",
    "from extract_feat import extract_feats_single_wav\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.constraints import maxnorm\n",
    "from keras.layers import Convolution1D, Dense, MaxPooling1D, Flatten, Add, Dropout, Input, Activation\n",
    "from keras.layers import TimeDistributed, Bidirectional, LSTM, LeakyReLU\n",
    "from keras.models import Sequential\n",
    "from keras import optimizers, regularizers\n",
    "from keras.utils import np_utils, to_categorical\n",
    "from keras.models import Model, load_model, Sequential\n",
    "from keras.regularizers import l2\n",
    "\n",
    "import keras\n",
    "\n",
    "from IPython.display import clear_output\n",
    "from tensorflow.python.client import device_lib\n",
    "from tensorflow.python.keras import backend\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "tf.keras.backend.clear_session()\n",
    "tf.compat.v1.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_emp_miu(y):\n",
    "    path = '..//models//emp_miu_class_' + str(y) + '.npy'\n",
    "    return np.load(path, allow_pickle=True)\n",
    "\n",
    "def load_inv_emp_covar():\n",
    "    path = '..//models//inv_emp_sigma.npy'\n",
    "    return np.load(path, allow_pickle=True)\n",
    "\n",
    "def load_mahalanobis_mean(y):\n",
    "    path = '..//models//mahalanobis_mean_class_' + str(y) + '.npy'\n",
    "    return np.load(path, allow_pickle=True)\n",
    "\n",
    "def load_mahalanobis_std(y, allow_pickle=True):\n",
    "    path = '..//models//mahalanobis_std_class_' + str(y) + '.npy'\n",
    "    return np.load(path)\n",
    "\n",
    "def load_mahalanobis_coeff(y, allow_pickle=True):\n",
    "    path = '..//models//mahalanobis_threshold_coefficient_class_' + str(y) + '.npy'\n",
    "    return np.load(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_in_distribution(x, predicted_y):\n",
    "    \n",
    "    assert(predicted_y == 0 or predicted_y == 1)\n",
    "       \n",
    "    emp_miu = load_emp_miu(predicted_y)\n",
    "    inv_emp_sigma = load_inv_emp_covar()\n",
    "    \n",
    "    m_mean = load_mahalanobis_mean(predicted_y)\n",
    "    m_std = load_mahalanobis_std(predicted_y)\n",
    "    coeff = load_mahalanobis_coeff(predicted_y)\n",
    "    \n",
    "    upper = m_mean + coeff*m_std\n",
    "    lower = m_mean - coeff*m_std\n",
    "    \n",
    "    penult_act = intermediate_layer_model.predict(x)\n",
    "\n",
    "    try:\n",
    "        m_dist = np.transpose(penult_act-emp_miu) @ inv_emp_sigma @ (penult_act-emp_miu)\n",
    "    except:\n",
    "        m_dist = (penult_act-emp_miu) * inv_emp_sigma * (penult_act-emp_miu)\n",
    "    \n",
    "    m_dist_norm = np.linalg.norm(m_dist)\n",
    "    \n",
    "    if lower < m_dist_norm and m_dist_norm < upper:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n",
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "tf.keras.backend.clear_session()\n",
    "tf.compat.v1.reset_default_graph()\n",
    "\n",
    "def mil_squared_error(y_true, y_pred):\n",
    "    return tf.keras.backend.square(tf.keras.backend.max(y_pred) - tf.keras.backend.max(y_true))\n",
    "\n",
    "adam = tf.keras.optimizers.Adam(learning_rate=1e-5)\n",
    "\n",
    "model = tf.keras.models.load_model('..//models//cnn.hdf5', custom_objects={'mil_squared_error': mil_squared_error, 'adam': adam})\n",
    "intermediate_layer_model = tf.keras.models.load_model('..//models//intermediate_layer_model_cnn.hdf5', custom_objects={'mil_squared_error': mil_squared_error, 'adam': adam})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_for_all_wavs(dest, label):\n",
    "    result = np.expand_dims(np.zeros((48, 272)), axis=0)\n",
    "\n",
    "    for wav in os.listdir(dest):\n",
    "        vec = extract_feats_single_wav(dest + wav)\n",
    "        if not str(vec.shape) == '(48, 272)':\n",
    "            continue\n",
    "        result = np.vstack((result, np.expand_dims(vec, axis=0)))\n",
    "\n",
    "    result = result[1:]\n",
    "    labels = np.expand_dims(np.asarray([label] * len(result)), axis=1)\n",
    "    print(result.shape)\n",
    "    print(labels.shape)\n",
    "\n",
    "    return result, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# this part assumes that the model is trained.\n",
    "# import sounds\n",
    "\n",
    "import shutil\n",
    "\n",
    "def identify(test_dir, threshold, distribution_measure_dir):\n",
    "    in_dist = []\n",
    "    out_dist = []\n",
    "    \n",
    "    for wav in os.listdir(test_dir):\n",
    "        \n",
    "        if not wav.endswith('wav'):\n",
    "            continue\n",
    "        else:\n",
    "            feat_vec = np.expand_dims(extract_feats_single_wav(test_dir + wav), axis=0)\n",
    "            softmax = np.squeeze(model.predict(feat_vec))\n",
    "            predicted_label = np.argmax(softmax)\n",
    "            \n",
    "            if is_in_distribution(feat_vec, predicted_label) and softmax[predicted_label] > threshold:\n",
    "                in_dist.append(feat_vec)\n",
    "                \n",
    "                shutil.copyfile(test_dir+wav, distribution_measure_dir + wav)\n",
    "                \n",
    "                #print('in distribution sample ' + wav)\n",
    "            else:\n",
    "                out_dist.append(feat_vec)\n",
    "\n",
    "            #print(str(len(in_dist) + len(out_dist)) + ' out of ' + str(len(os.listdir(test_dir))))\n",
    "            \n",
    "    #print('in distribution samples: ' + str(len(in_dist)))\n",
    "    #print('out of distribution samples: ' + str(len(out_dist)))\n",
    "    \n",
    "    return in_dist, out_dist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dirs = \"D://Karen's parents//\"\n",
    "distribution_measure_dirs = \"D://Karen's parents//in_distribution//\"\n",
    "\n",
    "for test_dir in os.listdir(test_dirs):\n",
    "    if \"parents\" in test_dir:\n",
    "        continue\n",
    "    else:\n",
    "        distribution_measurement_dir = distribution_measure_dirs + test_dir + '//'\n",
    "        dir_name = test_dir\n",
    "        test_dir = test_dirs + test_dir + '//'\n",
    "        \n",
    "        try:\n",
    "            shutil.rmtree(distribution_measure_dir)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        os.makedirs(distribution_measure_dir)\n",
    "        \n",
    "        in_dist, out_dist = identify(test_dir, 0.875, distribution_measure_dir)\n",
    "        \n",
    "        print(dir_name)\n",
    "        \n",
    "        try:\n",
    "            os.mkdirs(distribution_measure_dirs + dir_name)\n",
    "        except:\n",
    "            print(distribution_measure_dirs + dir_name + ' already exists.')\n",
    "        \n",
    "        np.save(distribution_measure_dirs + dir_name + '//distribution.npy', np.asarray([in_dist, out_dist]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('base': conda)",
   "language": "python",
   "name": "python37464bitbaseconda520b236a9c6d486bbc01b80a136b32a1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
