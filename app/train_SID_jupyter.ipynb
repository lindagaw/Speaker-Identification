{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "import time\n",
    "import datetime\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import pickle\n",
    "\n",
    "import random\n",
    "from xml.dom import minidom\n",
    "from librosa import load\n",
    "import shutil\n",
    "\n",
    "from extract_feat import extract_feats_single_wav\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
    "\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as sfs\n",
    "\n",
    "path_caregiver = '..//speaker_id_module//SpeakerID//singles//1-caregiver//'\n",
    "dest_caregiver = '..//app//2-Training//singles//1-caregiver//'\n",
    "\n",
    "path_patient = '..//speaker_id_module//SpeakerID//singles//2-patient//'\n",
    "dest_patient = '..//app//2-Training//singles//2-patient//'\n",
    "\n",
    "def slice_audios(path, dest):\n",
    "    for old_audio in os.listdir(dest):\n",
    "        os.remove(dest + old_audio)\n",
    "        \n",
    "    for audio_index in range(0, len(os.listdir(path))):\n",
    "        target_audio_path =  path + os.listdir(path)[audio_index]\n",
    "        print('input audio: ' + target_audio_path)\n",
    "\n",
    "        target_audio = AudioSegment.from_wav(target_audio_path)\n",
    "        target_duration = target_audio.duration_seconds\n",
    "\n",
    "        folds = int(target_duration/5.0)\n",
    "        for fold in range(0, folds+1):\n",
    "\n",
    "            start_time = time.time()\n",
    "\n",
    "            start_time = fold * 5000  # Works in milliseconds\n",
    "            end_time = (fold + 1) * 5000\n",
    "            new_audio = target_audio[start_time:end_time]\n",
    "\n",
    "            components = target_audio_path.split('/')\n",
    "            filename = components[len(components)-1]\n",
    "\n",
    "            new_audio_path = dest + filename[:len(filename)-4] + '_' + str(fold) + '.wav'\n",
    "            print('generated the slice of the audio segment at index ' + str(fold) )\n",
    "            new_audio.export(new_audio_path, format=\"wav\")\n",
    "\n",
    "def change_amplitude(emotionfile, d1, newSoundFile, d2):\n",
    "    \n",
    "    if d1 <= d2:\n",
    "        sound = AudioSegment.from_file(emotionfile) - np.random.randint(0, (6 * d2/d1 - 1))\n",
    "        sound.export(newSoundFile, format='wav')  ### save the new generated file in a folder\n",
    "    else:\n",
    "        print('Invalid distance parameters. d1 should be <= d2.')\n",
    "\n",
    "def change_amplitude_range(emotionfile, newSoundFile, threshold):\n",
    "    #amount = np.random.randint(0, threshold)\n",
    "    amount = random.uniform(0, threshold)\n",
    "    #print('Deamplify ' + str(emotionfile) + ' by ' + str(amount) + ' db.')\n",
    "    sound = AudioSegment.from_file(emotionfile) - amount\n",
    "    sound.export(newSoundFile, format='wav')  ### save the new generated file in a folder\n",
    "    return amount\n",
    "\n",
    "def deamplify_per_folder(directory):\n",
    "    for file in os.listdir(directory):\n",
    "        if file.endswith('.wav'):\n",
    "            soundFile = directory + file\n",
    "            newSoundFile = directory + 'deamplified_' + file\n",
    "            change_amplitude_range(soundFile, newSoundFile, 12)\n",
    "\n",
    "def add_noise_and_deamplify_per_folder(directory, extension, noise_directory):\n",
    "    for file in os.listdir(directory):\n",
    "        if file.endswith(extension) and not file[1] == '_':\n",
    "            for i in range(0, 2):\n",
    "                soundFile = directory + file\n",
    "                amount = change_amplitude_range(soundFile, soundFile, 6)\n",
    "                noise = random.choice(os.listdir(noise_directory))\n",
    "                random_noise = noise_directory + noise\n",
    "                newSoundFile = directory + 'deamp_' + str(amount) + '_noise_' + noise[:len(noise)-5] + '_' + file\n",
    "                add_noise_per_file(soundFile, random_noise, newSoundFile)\n",
    "                print(newSoundFile)\n",
    "\n",
    "def add_noise_per_file(emotionfile, bgnoise, newSoundFile):\n",
    "    \n",
    "    emotionsound = AudioSegment.from_wav(emotionfile)\n",
    "    emotion_duration = emotionsound.duration_seconds * 1000\n",
    "    noise = AudioSegment.from_wav(bgnoise)\n",
    "    noise_duration = noise.duration_seconds * 1000\n",
    "    \n",
    "    threshold = noise_duration - emotion_duration\n",
    "    \n",
    "    if threshold > 0:\n",
    "        overlay_start = np.random.randint(0, threshold)\n",
    "    else:\n",
    "        overlay_start = 0\n",
    "        \n",
    "    targeted_chunk = noise[overlay_start:overlay_start + emotion_duration]\n",
    "    newSound = emotionsound.overlay(targeted_chunk, position=0)\n",
    "    newSound=newSound[0:5000]\n",
    "    newSound.export(newSoundFile, format='wav')  ### save the new generated file in a folder\n",
    "\n",
    "def extract_features_for_all_wavs(dest, label):\n",
    "    result = np.expand_dims(np.zeros((48, 272)), axis=0)\n",
    "\n",
    "    for wav in os.listdir(dest):\n",
    "        vec = extract_feats_single_wav(dest + wav)\n",
    "        if not str(vec.shape) == '(48, 272)':\n",
    "            continue\n",
    "        result = np.vstack((result, np.expand_dims(vec, axis=0)))\n",
    "\n",
    "    result = result[1:]\n",
    "    labels = np.expand_dims(np.asarray([label] * len(result)), axis=1)\n",
    "    print(result.shape)\n",
    "    print(labels.shape)\n",
    "\n",
    "    return result, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.constraints import maxnorm\n",
    "from keras.layers import Convolution1D, Dense, MaxPooling1D, Flatten, Add, Dropout, Input, Activation\n",
    "from keras.layers import TimeDistributed, Bidirectional, LSTM, LeakyReLU\n",
    "from keras.models import Sequential\n",
    "from keras import optimizers, regularizers\n",
    "from keras.utils import np_utils, to_categorical\n",
    "from keras.models import Model, load_model, Sequential\n",
    "from keras.regularizers import l2\n",
    "\n",
    "import keras\n",
    "\n",
    "from IPython.display import clear_output\n",
    "from tensorflow.python.client import device_lib\n",
    "from tensorflow.python.keras import backend\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input audio: ..//speaker_id_module//SpeakerID//singles//1-caregiver//caregiver.wav\n",
      "generated the slice of the audio segment at index 0\n",
      "generated the slice of the audio segment at index 1\n",
      "generated the slice of the audio segment at index 2\n",
      "generated the slice of the audio segment at index 3\n",
      "generated the slice of the audio segment at index 4\n",
      "generated the slice of the audio segment at index 5\n",
      "generated the slice of the audio segment at index 6\n",
      "generated the slice of the audio segment at index 7\n",
      "generated the slice of the audio segment at index 8\n",
      "generated the slice of the audio segment at index 9\n",
      "generated the slice of the audio segment at index 10\n",
      "generated the slice of the audio segment at index 11\n",
      "generated the slice of the audio segment at index 12\n",
      "generated the slice of the audio segment at index 13\n",
      "generated the slice of the audio segment at index 14\n",
      "generated the slice of the audio segment at index 15\n",
      "generated the slice of the audio segment at index 16\n",
      "generated the slice of the audio segment at index 17\n",
      "generated the slice of the audio segment at index 18\n",
      "generated the slice of the audio segment at index 19\n",
      "generated the slice of the audio segment at index 20\n",
      "generated the slice of the audio segment at index 21\n",
      "generated the slice of the audio segment at index 22\n",
      "generated the slice of the audio segment at index 23\n",
      "generated the slice of the audio segment at index 24\n",
      "generated the slice of the audio segment at index 25\n",
      "generated the slice of the audio segment at index 26\n",
      "generated the slice of the audio segment at index 27\n",
      "generated the slice of the audio segment at index 28\n",
      "generated the slice of the audio segment at index 29\n",
      "generated the slice of the audio segment at index 30\n",
      "generated the slice of the audio segment at index 31\n",
      "generated the slice of the audio segment at index 32\n",
      "generated the slice of the audio segment at index 33\n",
      "generated the slice of the audio segment at index 34\n",
      "generated the slice of the audio segment at index 35\n",
      "generated the slice of the audio segment at index 36\n",
      "generated the slice of the audio segment at index 37\n",
      "generated the slice of the audio segment at index 38\n",
      "generated the slice of the audio segment at index 39\n",
      "generated the slice of the audio segment at index 40\n",
      "generated the slice of the audio segment at index 41\n",
      "generated the slice of the audio segment at index 42\n",
      "generated the slice of the audio segment at index 43\n",
      "generated the slice of the audio segment at index 44\n",
      "generated the slice of the audio segment at index 45\n",
      "generated the slice of the audio segment at index 46\n",
      "generated the slice of the audio segment at index 47\n",
      "generated the slice of the audio segment at index 48\n",
      "generated the slice of the audio segment at index 49\n",
      "generated the slice of the audio segment at index 50\n",
      "generated the slice of the audio segment at index 51\n",
      "generated the slice of the audio segment at index 52\n",
      "generated the slice of the audio segment at index 53\n",
      "generated the slice of the audio segment at index 54\n",
      "generated the slice of the audio segment at index 55\n",
      "generated the slice of the audio segment at index 56\n",
      "generated the slice of the audio segment at index 57\n",
      "generated the slice of the audio segment at index 58\n",
      "generated the slice of the audio segment at index 59\n",
      "input audio: ..//speaker_id_module//SpeakerID//singles//2-patient//patient.wav\n",
      "generated the slice of the audio segment at index 0\n",
      "generated the slice of the audio segment at index 1\n",
      "generated the slice of the audio segment at index 2\n",
      "generated the slice of the audio segment at index 3\n",
      "generated the slice of the audio segment at index 4\n",
      "generated the slice of the audio segment at index 5\n",
      "generated the slice of the audio segment at index 6\n",
      "generated the slice of the audio segment at index 7\n",
      "generated the slice of the audio segment at index 8\n",
      "generated the slice of the audio segment at index 9\n",
      "generated the slice of the audio segment at index 10\n",
      "generated the slice of the audio segment at index 11\n",
      "generated the slice of the audio segment at index 12\n",
      "generated the slice of the audio segment at index 13\n",
      "generated the slice of the audio segment at index 14\n",
      "generated the slice of the audio segment at index 15\n",
      "generated the slice of the audio segment at index 16\n",
      "generated the slice of the audio segment at index 17\n",
      "generated the slice of the audio segment at index 18\n",
      "generated the slice of the audio segment at index 19\n",
      "generated the slice of the audio segment at index 20\n",
      "generated the slice of the audio segment at index 21\n",
      "generated the slice of the audio segment at index 22\n",
      "generated the slice of the audio segment at index 23\n",
      "generated the slice of the audio segment at index 24\n",
      "generated the slice of the audio segment at index 25\n",
      "generated the slice of the audio segment at index 26\n",
      "generated the slice of the audio segment at index 27\n",
      "generated the slice of the audio segment at index 28\n",
      "generated the slice of the audio segment at index 29\n",
      "generated the slice of the audio segment at index 30\n",
      "generated the slice of the audio segment at index 31\n",
      "generated the slice of the audio segment at index 32\n",
      "generated the slice of the audio segment at index 33\n",
      "generated the slice of the audio segment at index 34\n",
      "generated the slice of the audio segment at index 35\n",
      "generated the slice of the audio segment at index 36\n",
      "generated the slice of the audio segment at index 37\n",
      "generated the slice of the audio segment at index 38\n",
      "generated the slice of the audio segment at index 39\n",
      "generated the slice of the audio segment at index 40\n",
      "generated the slice of the audio segment at index 41\n",
      "generated the slice of the audio segment at index 42\n",
      "generated the slice of the audio segment at index 43\n",
      "generated the slice of the audio segment at index 44\n",
      "generated the slice of the audio segment at index 45\n",
      "generated the slice of the audio segment at index 46\n",
      "generated the slice of the audio segment at index 47\n",
      "generated the slice of the audio segment at index 48\n",
      "generated the slice of the audio segment at index 49\n",
      "generated the slice of the audio segment at index 50\n",
      "generated the slice of the audio segment at index 51\n",
      "generated the slice of the audio segment at index 52\n",
      "generated the slice of the audio segment at index 53\n",
      "generated the slice of the audio segment at index 54\n",
      "generated the slice of the audio segment at index 55\n",
      "generated the slice of the audio segment at index 56\n",
      "generated the slice of the audio segment at index 57\n",
      "generated the slice of the audio segment at index 58\n",
      "generated the slice of the audio segment at index 59\n",
      "..//app//2-Training//singles//1-caregiver//deamp_5.270304894898613_noise_home_24_caregiver_0.wav\n",
      "..//app//2-Training//singles//1-caregiver//deamp_4.7121652798165385_noise_home_27_caregiver_0.wav\n",
      "..//app//2-Training//singles//1-caregiver//deamp_5.2943931359124985_noise_home_81_caregiver_1.wav\n",
      "..//app//2-Training//singles//1-caregiver//deamp_1.7462968305198951_noise_home_83_caregiver_1.wav\n",
      "..//app//2-Training//singles//1-caregiver//deamp_4.856972328188849_noise_home_22_caregiver_2.wav\n",
      "..//app//2-Training//singles//1-caregiver//deamp_5.737156888736922_noise_home_26_caregiver_2.wav\n",
      "..//app//2-Training//singles//1-caregiver//deamp_1.6044338437481964_noise_home_25_caregiver_3.wav\n",
      "..//app//2-Training//singles//1-caregiver//deamp_1.2589026858134096_noise_home_25_caregiver_3.wav\n",
      "..//app//2-Training//singles//1-caregiver//deamp_5.052954695042535_noise_home_2_caregiver_4.wav\n",
      "..//app//2-Training//singles//1-caregiver//deamp_1.0573055430000264_noise_home_81_caregiver_4.wav\n",
      "..//app//2-Training//singles//1-caregiver//deamp_4.0031075311824615_noise_home_2_caregiver_5.wav\n",
      "..//app//2-Training//singles//1-caregiver//deamp_3.7216109227695835_noise_home_88_caregiver_5.wav\n",
      "..//app//2-Training//singles//1-caregiver//deamp_4.047168773345217_noise_home_27_caregiver_6.wav\n",
      "..//app//2-Training//singles//1-caregiver//deamp_5.997109047036412_noise_home_80_caregiver_6.wav\n",
      "..//app//2-Training//singles//1-caregiver//deamp_2.566167333150049_noise_home_2_caregiver_7.wav\n",
      "..//app//2-Training//singles//1-caregiver//deamp_0.04140577752713548_noise_home_23_caregiver_7.wav\n",
      "..//app//2-Training//singles//1-caregiver//deamp_0.6912265011216736_noise_home_25_caregiver_8.wav\n",
      "..//app//2-Training//singles//1-caregiver//deamp_4.530071329971893_noise_home_25_caregiver_8.wav\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..//app//2-Training//singles//1-caregiver//deamp_1.332488361492251_noise_home_82_caregiver_9.wav\n",
      "..//app//2-Training//singles//1-caregiver//deamp_3.1097178981844067_noise_home_27_caregiver_9.wav\n",
      "..//app//2-Training//singles//1-caregiver//deamp_3.6564562257168705_noise_home_25_caregiver_10.wav\n",
      "..//app//2-Training//singles//1-caregiver//deamp_3.7447357689257585_noise_home_82_caregiver_10.wav\n",
      "..//app//2-Training//singles//1-caregiver//deamp_5.08082838970032_noise_home_88_caregiver_11.wav\n",
      "..//app//2-Training//singles//1-caregiver//deamp_4.739877500838018_noise_home_80_caregiver_11.wav\n",
      "..//app//2-Training//singles//1-caregiver//deamp_3.3445120771739125_noise_home_2_caregiver_12.wav\n",
      "..//app//2-Training//singles//1-caregiver//deamp_3.4822921672781906_noise_home_25_caregiver_12.wav\n",
      "..//app//2-Training//singles//1-caregiver//deamp_4.839261365345314_noise_home_2_caregiver_13.wav\n",
      "..//app//2-Training//singles//1-caregiver//deamp_5.685788503236472_noise_home_80_caregiver_13.wav\n",
      "..//app//2-Training//singles//1-caregiver//deamp_0.11839805845020202_noise_home_23_caregiver_14.wav\n",
      "..//app//2-Training//singles//1-caregiver//deamp_5.117201194173685_noise_home_83_caregiver_14.wav\n",
      "..//app//2-Training//singles//1-caregiver//deamp_3.0892723964408724_noise_home_81_caregiver_15.wav\n",
      "..//app//2-Training//singles//1-caregiver//deamp_0.35366293558611095_noise_home_88_caregiver_15.wav\n",
      "..//app//2-Training//singles//1-caregiver//deamp_2.082366653577969_noise_home_23_caregiver_16.wav\n",
      "..//app//2-Training//singles//1-caregiver//deamp_5.348187039332483_noise_home_80_caregiver_16.wav\n",
      "..//app//2-Training//singles//1-caregiver//deamp_3.269729938818549_noise_home_2_caregiver_17.wav\n",
      "..//app//2-Training//singles//1-caregiver//deamp_0.11965177679030403_noise_home_81_caregiver_17.wav\n",
      "..//app//2-Training//singles//1-caregiver//deamp_1.0087907761722972_noise_home_23_caregiver_18.wav\n",
      "..//app//2-Training//singles//1-caregiver//deamp_2.375417863315314_noise_home_83_caregiver_18.wav\n",
      "..//app//2-Training//singles//1-caregiver//deamp_4.693064041585205_noise_home_88_caregiver_19.wav\n",
      "..//app//2-Training//singles//1-caregiver//deamp_3.347611494469211_noise_home_82_caregiver_19.wav\n",
      "..//app//2-Training//singles//1-caregiver//deamp_2.623522192880235_noise_home_82_caregiver_20.wav\n",
      "..//app//2-Training//singles//1-caregiver//deamp_1.3593006882981746_noise_home_26_caregiver_20.wav\n",
      "..//app//2-Training//singles//1-caregiver//deamp_5.7429492865414336_noise_home_82_caregiver_21.wav\n",
      "..//app//2-Training//singles//1-caregiver//deamp_5.563984561127761_noise_home_22_caregiver_21.wav\n",
      "..//app//2-Training//singles//1-caregiver//deamp_3.1039736028378417_noise_home_25_caregiver_22.wav\n",
      "..//app//2-Training//singles//1-caregiver//deamp_2.554142072235206_noise_home_81_caregiver_22.wav\n",
      "..//app//2-Training//singles//1-caregiver//deamp_2.242621028470227_noise_home_23_caregiver_23.wav\n",
      "..//app//2-Training//singles//1-caregiver//deamp_5.417778054624581_noise_home_25_caregiver_23.wav\n",
      "..//app//2-Training//singles//1-caregiver//deamp_4.4288685783167265_noise_home_88_caregiver_24.wav\n",
      "..//app//2-Training//singles//1-caregiver//deamp_4.92946069546924_noise_home_82_caregiver_24.wav\n",
      "..//app//2-Training//singles//1-caregiver//deamp_3.905246479329404_noise_home_2_caregiver_25.wav\n",
      "..//app//2-Training//singles//1-caregiver//deamp_3.545222840749597_noise_home_23_caregiver_25.wav\n",
      "..//app//2-Training//singles//1-caregiver//deamp_5.1601197525076845_noise_home_80_caregiver_26.wav\n",
      "..//app//2-Training//singles//1-caregiver//deamp_1.3744826621134234_noise_home_81_caregiver_26.wav\n",
      "..//app//2-Training//singles//1-caregiver//deamp_2.984962464503604_noise_home_23_caregiver_27.wav\n",
      "..//app//2-Training//singles//1-caregiver//deamp_2.112538040929727_noise_home_2_caregiver_27.wav\n",
      "..//app//2-Training//singles//1-caregiver//deamp_2.796946588290334_noise_home_26_caregiver_28.wav\n",
      "..//app//2-Training//singles//1-caregiver//deamp_1.0026996525356935_noise_home_26_caregiver_28.wav\n",
      "..//app//2-Training//singles//1-caregiver//deamp_4.77278050180706_noise_home_81_caregiver_29.wav\n",
      "..//app//2-Training//singles//1-caregiver//deamp_3.8317597420022924_noise_home_81_caregiver_29.wav\n",
      "..//app//2-Training//singles//1-caregiver//deamp_0.8575710952664095_noise_home_2_caregiver_30.wav\n",
      "..//app//2-Training//singles//1-caregiver//deamp_1.7964719410843324_noise_home_24_caregiver_30.wav\n",
      "..//app//2-Training//singles//1-caregiver//deamp_0.8224236980868995_noise_home_24_caregiver_31.wav\n",
      "..//app//2-Training//singles//1-caregiver//deamp_2.8219413198655707_noise_home_83_caregiver_31.wav\n",
      "..//app//2-Training//singles//1-caregiver//deamp_4.474523007861129_noise_home_83_caregiver_32.wav\n",
      "..//app//2-Training//singles//1-caregiver//deamp_0.7498460540784695_noise_home_23_caregiver_32.wav\n",
      "..//app//2-Training//singles//1-caregiver//deamp_2.568287304506242_noise_home_26_caregiver_33.wav\n",
      "..//app//2-Training//singles//1-caregiver//deamp_0.6509766379617883_noise_home_83_caregiver_33.wav\n",
      "..//app//2-Training//singles//1-caregiver//deamp_3.9052362491543713_noise_home_23_caregiver_34.wav\n",
      "..//app//2-Training//singles//1-caregiver//deamp_5.95427503016461_noise_home_81_caregiver_34.wav\n",
      "..//app//2-Training//singles//1-caregiver//deamp_3.4742186078842057_noise_home_27_caregiver_35.wav\n",
      "..//app//2-Training//singles//1-caregiver//deamp_5.510221807170164_noise_home_23_caregiver_35.wav\n",
      "..//app//2-Training//singles//1-caregiver//deamp_2.257351298711151_noise_home_24_caregiver_36.wav\n",
      "..//app//2-Training//singles//1-caregiver//deamp_2.6884809636748748_noise_home_80_caregiver_36.wav\n",
      "..//app//2-Training//singles//1-caregiver//deamp_0.897457305905017_noise_home_27_caregiver_37.wav\n",
      "..//app//2-Training//singles//1-caregiver//deamp_3.6498006860970973_noise_home_82_caregiver_37.wav\n",
      "..//app//2-Training//singles//1-caregiver//deamp_1.5029356181367564_noise_home_80_caregiver_38.wav\n",
      "..//app//2-Training//singles//1-caregiver//deamp_4.54830906075913_noise_home_26_caregiver_38.wav\n",
      "..//app//2-Training//singles//1-caregiver//deamp_0.2740581400999682_noise_home_80_caregiver_39.wav\n",
      "..//app//2-Training//singles//1-caregiver//deamp_0.38905360364810004_noise_home_88_caregiver_39.wav\n",
      "..//app//2-Training//singles//1-caregiver//deamp_1.2518713323916675_noise_home_23_caregiver_40.wav\n",
      "..//app//2-Training//singles//1-caregiver//deamp_2.4040418844226714_noise_home_23_caregiver_40.wav\n",
      "..//app//2-Training//singles//1-caregiver//deamp_1.4896082888646485_noise_home_81_caregiver_41.wav\n",
      "..//app//2-Training//singles//1-caregiver//deamp_4.0930823589351375_noise_home_23_caregiver_41.wav\n",
      "..//app//2-Training//singles//1-caregiver//deamp_0.6212347723269467_noise_home_88_caregiver_42.wav\n",
      "..//app//2-Training//singles//1-caregiver//deamp_0.2974328395370902_noise_home_22_caregiver_42.wav\n",
      "..//app//2-Training//singles//1-caregiver//deamp_3.736986120798294_noise_home_26_caregiver_43.wav\n",
      "..//app//2-Training//singles//1-caregiver//deamp_4.762837109066831_noise_home_25_caregiver_43.wav\n",
      "..//app//2-Training//singles//1-caregiver//deamp_4.747390123417189_noise_home_80_caregiver_44.wav\n",
      "..//app//2-Training//singles//1-caregiver//deamp_0.8967422389489277_noise_home_82_caregiver_44.wav\n",
      "..//app//2-Training//singles//1-caregiver//deamp_4.33624397450209_noise_home_26_caregiver_45.wav\n",
      "..//app//2-Training//singles//1-caregiver//deamp_1.4153546432120871_noise_home_23_caregiver_45.wav\n",
      "..//app//2-Training//singles//1-caregiver//deamp_5.308786673837373_noise_home_24_caregiver_46.wav\n",
      "..//app//2-Training//singles//1-caregiver//deamp_1.8283711987297484_noise_home_81_caregiver_46.wav\n",
      "..//app//2-Training//singles//1-caregiver//deamp_3.3688597689578286_noise_home_23_caregiver_47.wav\n",
      "..//app//2-Training//singles//1-caregiver//deamp_1.0995188133872948_noise_home_82_caregiver_47.wav\n",
      "..//app//2-Training//singles//1-caregiver//deamp_3.20015249413259_noise_home_23_caregiver_48.wav\n",
      "..//app//2-Training//singles//1-caregiver//deamp_5.06631084674059_noise_home_81_caregiver_48.wav\n",
      "..//app//2-Training//singles//1-caregiver//deamp_4.882094459393971_noise_home_26_caregiver_49.wav\n",
      "..//app//2-Training//singles//1-caregiver//deamp_4.126248717204482_noise_home_80_caregiver_49.wav\n",
      "..//app//2-Training//singles//1-caregiver//deamp_3.9953223316815434_noise_home_24_caregiver_50.wav\n",
      "..//app//2-Training//singles//1-caregiver//deamp_3.425703287235483_noise_home_88_caregiver_50.wav\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..//app//2-Training//singles//1-caregiver//deamp_3.3465629757480695_noise_home_22_caregiver_51.wav\n",
      "..//app//2-Training//singles//1-caregiver//deamp_2.751932477690522_noise_home_26_caregiver_51.wav\n",
      "..//app//2-Training//singles//1-caregiver//deamp_5.73075295742193_noise_home_83_caregiver_52.wav\n",
      "..//app//2-Training//singles//1-caregiver//deamp_0.19233157091554265_noise_home_88_caregiver_52.wav\n",
      "..//app//2-Training//singles//1-caregiver//deamp_1.5597850430539297_noise_home_82_caregiver_53.wav\n",
      "..//app//2-Training//singles//1-caregiver//deamp_4.518751400704388_noise_home_81_caregiver_53.wav\n",
      "..//app//2-Training//singles//1-caregiver//deamp_2.9439320122442756_noise_home_2_caregiver_54.wav\n",
      "..//app//2-Training//singles//1-caregiver//deamp_1.7776300720920013_noise_home_22_caregiver_54.wav\n",
      "..//app//2-Training//singles//1-caregiver//deamp_1.2105199963245301_noise_home_23_caregiver_55.wav\n",
      "..//app//2-Training//singles//1-caregiver//deamp_5.40777879025104_noise_home_25_caregiver_55.wav\n",
      "..//app//2-Training//singles//1-caregiver//deamp_4.153297187494076_noise_home_88_caregiver_56.wav\n",
      "..//app//2-Training//singles//1-caregiver//deamp_4.875486061176236_noise_home_23_caregiver_56.wav\n",
      "..//app//2-Training//singles//1-caregiver//deamp_5.819123879385343_noise_home_81_caregiver_57.wav\n",
      "..//app//2-Training//singles//1-caregiver//deamp_0.6974738735221566_noise_home_81_caregiver_57.wav\n",
      "..//app//2-Training//singles//1-caregiver//deamp_5.098508870657646_noise_home_88_caregiver_58.wav\n",
      "..//app//2-Training//singles//1-caregiver//deamp_4.992181814685667_noise_home_83_caregiver_58.wav\n",
      "..//app//2-Training//singles//1-caregiver//deamp_1.959743167271969_noise_home_81_caregiver_59.wav\n",
      "..//app//2-Training//singles//1-caregiver//deamp_4.345719826370029_noise_home_81_caregiver_59.wav\n",
      "..//app//2-Training//singles//2-patient//deamp_1.5479616571567316_noise_home_23_patient_0.wav\n",
      "..//app//2-Training//singles//2-patient//deamp_5.6082472325537776_noise_home_2_patient_0.wav\n",
      "..//app//2-Training//singles//2-patient//deamp_4.384758952022338_noise_home_82_patient_1.wav\n",
      "..//app//2-Training//singles//2-patient//deamp_5.5517476303503575_noise_home_2_patient_1.wav\n",
      "..//app//2-Training//singles//2-patient//deamp_4.960222566841479_noise_home_81_patient_2.wav\n",
      "..//app//2-Training//singles//2-patient//deamp_4.397049092550505_noise_home_80_patient_2.wav\n",
      "..//app//2-Training//singles//2-patient//deamp_2.476134691757852_noise_home_81_patient_3.wav\n",
      "..//app//2-Training//singles//2-patient//deamp_1.3927037186935982_noise_home_23_patient_3.wav\n",
      "..//app//2-Training//singles//2-patient//deamp_1.0728451586179448_noise_home_81_patient_4.wav\n",
      "..//app//2-Training//singles//2-patient//deamp_2.3776777028716802_noise_home_23_patient_4.wav\n",
      "..//app//2-Training//singles//2-patient//deamp_3.4060939590933104_noise_home_82_patient_5.wav\n",
      "..//app//2-Training//singles//2-patient//deamp_2.871140891843361_noise_home_88_patient_5.wav\n",
      "..//app//2-Training//singles//2-patient//deamp_4.460249124651519_noise_home_23_patient_6.wav\n",
      "..//app//2-Training//singles//2-patient//deamp_1.2417159711330832_noise_home_24_patient_6.wav\n",
      "..//app//2-Training//singles//2-patient//deamp_1.6587758742222243_noise_home_82_patient_7.wav\n",
      "..//app//2-Training//singles//2-patient//deamp_5.892709771198437_noise_home_80_patient_7.wav\n",
      "..//app//2-Training//singles//2-patient//deamp_2.6034039023917144_noise_home_80_patient_8.wav\n",
      "..//app//2-Training//singles//2-patient//deamp_1.4768875016371532_noise_home_83_patient_8.wav\n",
      "..//app//2-Training//singles//2-patient//deamp_5.160250659695976_noise_home_26_patient_9.wav\n",
      "..//app//2-Training//singles//2-patient//deamp_1.5411929741031305_noise_home_27_patient_9.wav\n",
      "..//app//2-Training//singles//2-patient//deamp_0.5845635281429404_noise_home_80_patient_10.wav\n",
      "..//app//2-Training//singles//2-patient//deamp_3.001850176320629_noise_home_26_patient_10.wav\n",
      "..//app//2-Training//singles//2-patient//deamp_3.538129032319451_noise_home_80_patient_11.wav\n",
      "..//app//2-Training//singles//2-patient//deamp_1.2143823619810508_noise_home_80_patient_11.wav\n",
      "..//app//2-Training//singles//2-patient//deamp_1.4643073748352184_noise_home_83_patient_12.wav\n",
      "..//app//2-Training//singles//2-patient//deamp_2.6989656565156466_noise_home_23_patient_12.wav\n",
      "..//app//2-Training//singles//2-patient//deamp_0.9179650044061693_noise_home_22_patient_13.wav\n",
      "..//app//2-Training//singles//2-patient//deamp_5.892711702058579_noise_home_81_patient_13.wav\n",
      "..//app//2-Training//singles//2-patient//deamp_2.3785421327118623_noise_home_83_patient_14.wav\n",
      "..//app//2-Training//singles//2-patient//deamp_5.307622383686394_noise_home_26_patient_14.wav\n",
      "..//app//2-Training//singles//2-patient//deamp_1.4619751670179761_noise_home_81_patient_15.wav\n",
      "..//app//2-Training//singles//2-patient//deamp_0.873603978002202_noise_home_23_patient_15.wav\n",
      "..//app//2-Training//singles//2-patient//deamp_3.2150166702807947_noise_home_24_patient_16.wav\n",
      "..//app//2-Training//singles//2-patient//deamp_2.475783559945956_noise_home_88_patient_16.wav\n",
      "..//app//2-Training//singles//2-patient//deamp_2.613730795102744_noise_home_27_patient_17.wav\n",
      "..//app//2-Training//singles//2-patient//deamp_4.08776275440204_noise_home_25_patient_17.wav\n",
      "..//app//2-Training//singles//2-patient//deamp_0.7857561022122332_noise_home_26_patient_18.wav\n",
      "..//app//2-Training//singles//2-patient//deamp_1.0069197516471309_noise_home_25_patient_18.wav\n",
      "..//app//2-Training//singles//2-patient//deamp_0.8506204132176172_noise_home_83_patient_19.wav\n",
      "..//app//2-Training//singles//2-patient//deamp_5.789523680935842_noise_home_82_patient_19.wav\n",
      "..//app//2-Training//singles//2-patient//deamp_4.961050000190452_noise_home_80_patient_20.wav\n",
      "..//app//2-Training//singles//2-patient//deamp_0.9177691407337105_noise_home_23_patient_20.wav\n",
      "..//app//2-Training//singles//2-patient//deamp_4.799820804693316_noise_home_27_patient_21.wav\n",
      "..//app//2-Training//singles//2-patient//deamp_3.9121414961455816_noise_home_81_patient_21.wav\n",
      "..//app//2-Training//singles//2-patient//deamp_2.765907072711922_noise_home_82_patient_22.wav\n",
      "..//app//2-Training//singles//2-patient//deamp_4.198286258430527_noise_home_26_patient_22.wav\n",
      "..//app//2-Training//singles//2-patient//deamp_1.5676498598221296_noise_home_81_patient_23.wav\n",
      "..//app//2-Training//singles//2-patient//deamp_0.8294491683976113_noise_home_80_patient_23.wav\n",
      "..//app//2-Training//singles//2-patient//deamp_1.270007767995209_noise_home_82_patient_24.wav\n",
      "..//app//2-Training//singles//2-patient//deamp_0.3117335540981869_noise_home_81_patient_24.wav\n",
      "..//app//2-Training//singles//2-patient//deamp_3.624507846140404_noise_home_23_patient_25.wav\n",
      "..//app//2-Training//singles//2-patient//deamp_0.02248173437895784_noise_home_81_patient_25.wav\n",
      "..//app//2-Training//singles//2-patient//deamp_4.801386081889764_noise_home_2_patient_26.wav\n",
      "..//app//2-Training//singles//2-patient//deamp_0.144097232547445_noise_home_23_patient_26.wav\n",
      "..//app//2-Training//singles//2-patient//deamp_5.256079101454156_noise_home_82_patient_27.wav\n",
      "..//app//2-Training//singles//2-patient//deamp_2.362386351246864_noise_home_81_patient_27.wav\n",
      "..//app//2-Training//singles//2-patient//deamp_0.43741569317048756_noise_home_23_patient_28.wav\n",
      "..//app//2-Training//singles//2-patient//deamp_1.6094965731828046_noise_home_2_patient_28.wav\n",
      "..//app//2-Training//singles//2-patient//deamp_5.478067828844745_noise_home_2_patient_29.wav\n",
      "..//app//2-Training//singles//2-patient//deamp_4.749383627518807_noise_home_23_patient_29.wav\n",
      "..//app//2-Training//singles//2-patient//deamp_4.087847623459385_noise_home_82_patient_30.wav\n",
      "..//app//2-Training//singles//2-patient//deamp_5.598329578244329_noise_home_25_patient_30.wav\n",
      "..//app//2-Training//singles//2-patient//deamp_2.779666931271393_noise_home_2_patient_31.wav\n",
      "..//app//2-Training//singles//2-patient//deamp_1.5813534976544994_noise_home_24_patient_31.wav\n",
      "..//app//2-Training//singles//2-patient//deamp_3.1617346858249586_noise_home_26_patient_32.wav\n",
      "..//app//2-Training//singles//2-patient//deamp_5.973335004456471_noise_home_25_patient_32.wav\n",
      "..//app//2-Training//singles//2-patient//deamp_3.1574370439510373_noise_home_26_patient_33.wav\n",
      "..//app//2-Training//singles//2-patient//deamp_0.5322325078615133_noise_home_24_patient_33.wav\n",
      "..//app//2-Training//singles//2-patient//deamp_1.805028896931101_noise_home_82_patient_34.wav\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..//app//2-Training//singles//2-patient//deamp_3.65034075503405_noise_home_24_patient_34.wav\n",
      "..//app//2-Training//singles//2-patient//deamp_3.6169933784152715_noise_home_82_patient_35.wav\n",
      "..//app//2-Training//singles//2-patient//deamp_2.610435311852764_noise_home_23_patient_35.wav\n",
      "..//app//2-Training//singles//2-patient//deamp_1.026687551826642_noise_home_2_patient_36.wav\n",
      "..//app//2-Training//singles//2-patient//deamp_4.369336146946861_noise_home_24_patient_36.wav\n",
      "..//app//2-Training//singles//2-patient//deamp_1.638042457987909_noise_home_88_patient_37.wav\n",
      "..//app//2-Training//singles//2-patient//deamp_1.6942384180274572_noise_home_80_patient_37.wav\n",
      "..//app//2-Training//singles//2-patient//deamp_1.2615519062212788_noise_home_27_patient_38.wav\n",
      "..//app//2-Training//singles//2-patient//deamp_2.618063788974895_noise_home_23_patient_38.wav\n",
      "..//app//2-Training//singles//2-patient//deamp_2.4224083277845194_noise_home_83_patient_39.wav\n",
      "..//app//2-Training//singles//2-patient//deamp_0.8998723613978539_noise_home_83_patient_39.wav\n",
      "..//app//2-Training//singles//2-patient//deamp_4.583421122927028_noise_home_24_patient_40.wav\n",
      "..//app//2-Training//singles//2-patient//deamp_3.02115652049915_noise_home_25_patient_40.wav\n",
      "..//app//2-Training//singles//2-patient//deamp_1.739403942692183_noise_home_88_patient_41.wav\n",
      "..//app//2-Training//singles//2-patient//deamp_1.1230254235808215_noise_home_23_patient_41.wav\n",
      "..//app//2-Training//singles//2-patient//deamp_4.792709659820008_noise_home_82_patient_42.wav\n",
      "..//app//2-Training//singles//2-patient//deamp_4.53182999275076_noise_home_23_patient_42.wav\n",
      "..//app//2-Training//singles//2-patient//deamp_0.7400697538695276_noise_home_2_patient_43.wav\n",
      "..//app//2-Training//singles//2-patient//deamp_5.396704604923611_noise_home_82_patient_43.wav\n",
      "..//app//2-Training//singles//2-patient//deamp_5.33352903529639_noise_home_88_patient_44.wav\n",
      "..//app//2-Training//singles//2-patient//deamp_5.382370208007448_noise_home_23_patient_44.wav\n",
      "..//app//2-Training//singles//2-patient//deamp_4.593852804922028_noise_home_25_patient_45.wav\n",
      "..//app//2-Training//singles//2-patient//deamp_3.645530046626354_noise_home_88_patient_45.wav\n",
      "..//app//2-Training//singles//2-patient//deamp_1.081839439460313_noise_home_26_patient_46.wav\n",
      "..//app//2-Training//singles//2-patient//deamp_4.552080044316634_noise_home_22_patient_46.wav\n",
      "..//app//2-Training//singles//2-patient//deamp_3.4605437376439694_noise_home_24_patient_47.wav\n",
      "..//app//2-Training//singles//2-patient//deamp_5.746502365291692_noise_home_23_patient_47.wav\n",
      "..//app//2-Training//singles//2-patient//deamp_1.1868432000619635_noise_home_26_patient_48.wav\n",
      "..//app//2-Training//singles//2-patient//deamp_0.834102906216718_noise_home_27_patient_48.wav\n",
      "..//app//2-Training//singles//2-patient//deamp_1.5452352024381202_noise_home_81_patient_49.wav\n",
      "..//app//2-Training//singles//2-patient//deamp_3.2870208947375072_noise_home_88_patient_49.wav\n",
      "..//app//2-Training//singles//2-patient//deamp_1.1287546594960576_noise_home_2_patient_50.wav\n",
      "..//app//2-Training//singles//2-patient//deamp_1.2523436677296536_noise_home_80_patient_50.wav\n",
      "..//app//2-Training//singles//2-patient//deamp_1.696564827565722_noise_home_26_patient_51.wav\n",
      "..//app//2-Training//singles//2-patient//deamp_3.6913065796319198_noise_home_23_patient_51.wav\n",
      "..//app//2-Training//singles//2-patient//deamp_4.472635885808989_noise_home_2_patient_52.wav\n",
      "..//app//2-Training//singles//2-patient//deamp_3.683243429917046_noise_home_2_patient_52.wav\n",
      "..//app//2-Training//singles//2-patient//deamp_3.845142903811563_noise_home_23_patient_53.wav\n",
      "..//app//2-Training//singles//2-patient//deamp_3.523819662262185_noise_home_26_patient_53.wav\n",
      "..//app//2-Training//singles//2-patient//deamp_4.150895012528307_noise_home_80_patient_54.wav\n",
      "..//app//2-Training//singles//2-patient//deamp_2.284679953593816_noise_home_26_patient_54.wav\n",
      "..//app//2-Training//singles//2-patient//deamp_2.7194806985083493_noise_home_81_patient_55.wav\n",
      "..//app//2-Training//singles//2-patient//deamp_1.4573847156385569_noise_home_23_patient_55.wav\n",
      "..//app//2-Training//singles//2-patient//deamp_1.5063240642014588_noise_home_2_patient_56.wav\n",
      "..//app//2-Training//singles//2-patient//deamp_2.9113186308891326_noise_home_2_patient_56.wav\n",
      "..//app//2-Training//singles//2-patient//deamp_4.548842481452217_noise_home_81_patient_57.wav\n",
      "..//app//2-Training//singles//2-patient//deamp_0.04510569188212199_noise_home_2_patient_57.wav\n",
      "..//app//2-Training//singles//2-patient//deamp_4.027028747943457_noise_home_80_patient_58.wav\n",
      "..//app//2-Training//singles//2-patient//deamp_2.8252271159283233_noise_home_80_patient_58.wav\n",
      "..//app//2-Training//singles//2-patient//deamp_0.08731805186913588_noise_home_23_patient_59.wav\n",
      "..//app//2-Training//singles//2-patient//deamp_4.420562443161168_noise_home_81_patient_59.wav\n"
     ]
    }
   ],
   "source": [
    "# STEP 1: slice into 5-second wavs\n",
    "slice_audios(path_caregiver, dest_caregiver)\n",
    "slice_audios(path_patient, dest_patient)\n",
    "noise_directory = '..//noise_home//'\n",
    "\n",
    "add_noise_and_deamplify_per_folder(dest_caregiver, '.wav', noise_directory)\n",
    "add_noise_and_deamplify_per_folder(dest_patient, '.wav', noise_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(177, 48, 272)\n",
      "(177, 1)\n",
      "(180, 48, 272)\n",
      "(180, 1)\n"
     ]
    }
   ],
   "source": [
    "# Step 2: get the vecs of shape (X, 48, 272)\n",
    "X_caregiver, y_caregiver = extract_features_for_all_wavs(dest_caregiver, 0)\n",
    "X_patient, y_patient = extract_features_for_all_wavs(dest_patient, 1)\n",
    "\n",
    "X = np.vstack((X_caregiver, X_patient))\n",
    "y = to_categorical( np.vstack((y_caregiver, y_patient)) )\n",
    "\n",
    "#nsamples, nx, ny = X.shape\n",
    "#X = X.reshape((nsamples,nx*ny))\n",
    "\n",
    "X, X_test, y, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.constraints import maxnorm\n",
    "from keras.layers import Convolution1D, Dense, MaxPooling1D, Flatten, Add, Dropout, Input, Activation\n",
    "from keras.layers import TimeDistributed, Bidirectional, LSTM, LeakyReLU\n",
    "from keras.models import Sequential\n",
    "from keras import optimizers, regularizers\n",
    "from keras.utils import np_utils, to_categorical\n",
    "from keras.models import Model, load_model, Sequential\n",
    "from keras.regularizers import l2\n",
    "\n",
    "import keras\n",
    "\n",
    "from IPython.display import clear_output\n",
    "from tensorflow.python.client import device_lib\n",
    "from tensorflow.python.keras import backend\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "tf.keras.backend.clear_session()\n",
    "tf.compat.v1.reset_default_graph()\n",
    "\n",
    "def mil_squared_error(y_true, y_pred):\n",
    "    return tf.keras.backend.square(tf.keras.backend.max(y_pred) - tf.keras.backend.max(y_true))\n",
    "\n",
    "adam = tf.keras.optimizers.Adam(learning_rate=1e-5)\n",
    "\n",
    "def train_cnn():\n",
    "\n",
    "    model = keras.Sequential()\n",
    "    model.add(Convolution1D(filters= 1500, kernel_size=2, strides=2, activation='relu', input_shape=X_train[0].shape))\n",
    "    model.add(MaxPooling1D(2))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    #model = keras.Sequential()\n",
    "    model.add(Convolution1D(filters= 500, kernel_size=2, strides=2, activation='relu'))\n",
    "    model.add(MaxPooling1D(2))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    '''\n",
    "    model = keras.Sequential()\n",
    "    model.add(Convolution1D(filters= 500, kernel_size=1, strides=1, activation='relu'))\n",
    "    model.add(MaxPooling1D(2))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model = keras.Sequential()\n",
    "    model.add(Convolution1D(filters= 500, kernel_size=2, strides=2, activation='relu'))\n",
    "    model.add(MaxPooling1D(2))\n",
    "    model.add(Dropout(0.2))\n",
    "    '''\n",
    "    \n",
    "    model.add(Flatten())\n",
    "\n",
    "    for i in range(0, 1):\n",
    "        model.add(Dense(256, activation=\"relu\"))\n",
    "        model.add(Dropout(0.2))\n",
    "    model.add(Dense(2, activation=\"softmax\"))\n",
    "    model.compile(loss=['categorical_crossentropy'], optimizer=adam, metrics=['accuracy', mil_squared_error])\n",
    "    \n",
    "    print(\"Fit model on training data\")\n",
    "    history = model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        batch_size=64,\n",
    "        epochs=150,\n",
    "        validation_data=(X_val, y_val), verbose=1\n",
    "    )\n",
    "\n",
    "    #from sklearn.metrics import f1_score\n",
    "\n",
    "    y_preds = [np.argmax(val) for val in model.predict(X_test)]\n",
    "    y_trues = [np.argmax(val) for val in y_test]\n",
    "    print(accuracy_score(y_trues, y_preds))\n",
    "\n",
    "    model.save('..//models//cnn.hdf5')\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit model on training data\n",
      "Train on 179 samples, validate on 60 samples\n",
      "Epoch 1/150\n",
      "179/179 [==============================] - 1s 5ms/step - loss: 0.7027 - accuracy: 0.4749 - mil_squared_error: 0.1673 - val_loss: 0.6965 - val_accuracy: 0.4667 - val_mil_squared_error: 0.1993\n",
      "Epoch 2/150\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6993 - accuracy: 0.4749 - mil_squared_error: 0.1670 - val_loss: 0.6937 - val_accuracy: 0.4500 - val_mil_squared_error: 0.2050\n",
      "Epoch 3/150\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6944 - accuracy: 0.4972 - mil_squared_error: 0.1575 - val_loss: 0.6906 - val_accuracy: 0.4667 - val_mil_squared_error: 0.2090\n",
      "Epoch 4/150\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6771 - accuracy: 0.5866 - mil_squared_error: 0.1649 - val_loss: 0.6877 - val_accuracy: 0.5000 - val_mil_squared_error: 0.2114\n",
      "Epoch 5/150\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.6739 - accuracy: 0.5978 - mil_squared_error: 0.1659 - val_loss: 0.6848 - val_accuracy: 0.5667 - val_mil_squared_error: 0.2112\n",
      "Epoch 6/150\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6696 - accuracy: 0.6480 - mil_squared_error: 0.1606 - val_loss: 0.6819 - val_accuracy: 0.6000 - val_mil_squared_error: 0.2108\n",
      "Epoch 7/150\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6721 - accuracy: 0.6425 - mil_squared_error: 0.1678 - val_loss: 0.6791 - val_accuracy: 0.6667 - val_mil_squared_error: 0.2112\n",
      "Epoch 8/150\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.6607 - accuracy: 0.6816 - mil_squared_error: 0.1521 - val_loss: 0.6760 - val_accuracy: 0.6667 - val_mil_squared_error: 0.2097\n",
      "Epoch 9/150\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.6670 - accuracy: 0.6704 - mil_squared_error: 0.1643 - val_loss: 0.6730 - val_accuracy: 0.7167 - val_mil_squared_error: 0.2076\n",
      "Epoch 10/150\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6514 - accuracy: 0.7598 - mil_squared_error: 0.1572 - val_loss: 0.6698 - val_accuracy: 0.7000 - val_mil_squared_error: 0.2034\n",
      "Epoch 11/150\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6503 - accuracy: 0.7095 - mil_squared_error: 0.1399 - val_loss: 0.6664 - val_accuracy: 0.7500 - val_mil_squared_error: 0.1986\n",
      "Epoch 12/150\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6488 - accuracy: 0.7598 - mil_squared_error: 0.1533 - val_loss: 0.6630 - val_accuracy: 0.7667 - val_mil_squared_error: 0.1943\n",
      "Epoch 13/150\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.6569 - accuracy: 0.6648 - mil_squared_error: 0.1591 - val_loss: 0.6597 - val_accuracy: 0.8167 - val_mil_squared_error: 0.1909\n",
      "Epoch 14/150\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6448 - accuracy: 0.7374 - mil_squared_error: 0.1488 - val_loss: 0.6563 - val_accuracy: 0.8333 - val_mil_squared_error: 0.1871\n",
      "Epoch 15/150\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.6398 - accuracy: 0.7486 - mil_squared_error: 0.1488 - val_loss: 0.6528 - val_accuracy: 0.8500 - val_mil_squared_error: 0.1818\n",
      "Epoch 16/150\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6397 - accuracy: 0.7709 - mil_squared_error: 0.1451 - val_loss: 0.6493 - val_accuracy: 0.8667 - val_mil_squared_error: 0.1776\n",
      "Epoch 17/150\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6370 - accuracy: 0.7765 - mil_squared_error: 0.1408 - val_loss: 0.6458 - val_accuracy: 0.8667 - val_mil_squared_error: 0.1738\n",
      "Epoch 18/150\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6114 - accuracy: 0.8492 - mil_squared_error: 0.1360 - val_loss: 0.6424 - val_accuracy: 0.8667 - val_mil_squared_error: 0.1701\n",
      "Epoch 19/150\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.6250 - accuracy: 0.7989 - mil_squared_error: 0.1307 - val_loss: 0.6387 - val_accuracy: 0.8833 - val_mil_squared_error: 0.1660\n",
      "Epoch 20/150\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6112 - accuracy: 0.8715 - mil_squared_error: 0.1358 - val_loss: 0.6350 - val_accuracy: 0.8833 - val_mil_squared_error: 0.1611\n",
      "Epoch 21/150\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6070 - accuracy: 0.8939 - mil_squared_error: 0.1267 - val_loss: 0.6313 - val_accuracy: 0.8833 - val_mil_squared_error: 0.1584\n",
      "Epoch 22/150\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5971 - accuracy: 0.8436 - mil_squared_error: 0.1155 - val_loss: 0.6275 - val_accuracy: 0.8833 - val_mil_squared_error: 0.1555\n",
      "Epoch 23/150\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.6089 - accuracy: 0.8380 - mil_squared_error: 0.1131 - val_loss: 0.6238 - val_accuracy: 0.8833 - val_mil_squared_error: 0.1534\n",
      "Epoch 24/150\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6001 - accuracy: 0.8659 - mil_squared_error: 0.1099 - val_loss: 0.6200 - val_accuracy: 0.8833 - val_mil_squared_error: 0.1517\n",
      "Epoch 25/150\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5856 - accuracy: 0.8883 - mil_squared_error: 0.1115 - val_loss: 0.6161 - val_accuracy: 0.8833 - val_mil_squared_error: 0.1487\n",
      "Epoch 26/150\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.5912 - accuracy: 0.8771 - mil_squared_error: 0.1075 - val_loss: 0.6123 - val_accuracy: 0.9000 - val_mil_squared_error: 0.1467\n",
      "Epoch 27/150\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.5777 - accuracy: 0.8771 - mil_squared_error: 0.1074 - val_loss: 0.6080 - val_accuracy: 0.9000 - val_mil_squared_error: 0.1432\n",
      "Epoch 28/150\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5746 - accuracy: 0.9050 - mil_squared_error: 0.1098 - val_loss: 0.6034 - val_accuracy: 0.9000 - val_mil_squared_error: 0.1383\n",
      "Epoch 29/150\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5648 - accuracy: 0.9106 - mil_squared_error: 0.0952 - val_loss: 0.5988 - val_accuracy: 0.9000 - val_mil_squared_error: 0.1336\n",
      "Epoch 30/150\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.5523 - accuracy: 0.9274 - mil_squared_error: 0.0967 - val_loss: 0.5941 - val_accuracy: 0.9000 - val_mil_squared_error: 0.1288\n",
      "Epoch 31/150\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.5617 - accuracy: 0.9106 - mil_squared_error: 0.0948 - val_loss: 0.5895 - val_accuracy: 0.9000 - val_mil_squared_error: 0.1256\n",
      "Epoch 32/150\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.5625 - accuracy: 0.9106 - mil_squared_error: 0.0967 - val_loss: 0.5846 - val_accuracy: 0.9000 - val_mil_squared_error: 0.1207\n",
      "Epoch 33/150\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5396 - accuracy: 0.9609 - mil_squared_error: 0.0941 - val_loss: 0.5799 - val_accuracy: 0.9000 - val_mil_squared_error: 0.1175\n",
      "Epoch 34/150\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.5439 - accuracy: 0.9106 - mil_squared_error: 0.0752 - val_loss: 0.5751 - val_accuracy: 0.9000 - val_mil_squared_error: 0.1137\n",
      "Epoch 35/150\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.5395 - accuracy: 0.9385 - mil_squared_error: 0.0851 - val_loss: 0.5704 - val_accuracy: 0.9000 - val_mil_squared_error: 0.1111\n",
      "Epoch 36/150\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5301 - accuracy: 0.9385 - mil_squared_error: 0.0734 - val_loss: 0.5657 - val_accuracy: 0.9000 - val_mil_squared_error: 0.1077\n",
      "Epoch 37/150\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.5120 - accuracy: 0.9665 - mil_squared_error: 0.0808 - val_loss: 0.5606 - val_accuracy: 0.9000 - val_mil_squared_error: 0.1029\n",
      "Epoch 38/150\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5227 - accuracy: 0.9665 - mil_squared_error: 0.0727 - val_loss: 0.5557 - val_accuracy: 0.9000 - val_mil_squared_error: 0.0995\n",
      "Epoch 39/150\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5205 - accuracy: 0.9162 - mil_squared_error: 0.0792 - val_loss: 0.5502 - val_accuracy: 0.9000 - val_mil_squared_error: 0.0935\n",
      "Epoch 40/150\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.5052 - accuracy: 0.9441 - mil_squared_error: 0.0727 - val_loss: 0.5451 - val_accuracy: 0.9000 - val_mil_squared_error: 0.0894\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/150\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.4989 - accuracy: 0.9553 - mil_squared_error: 0.0600 - val_loss: 0.5400 - val_accuracy: 0.9000 - val_mil_squared_error: 0.0858\n",
      "Epoch 42/150\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.5024 - accuracy: 0.9274 - mil_squared_error: 0.0700 - val_loss: 0.5347 - val_accuracy: 0.9167 - val_mil_squared_error: 0.0814\n",
      "Epoch 43/150\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.4813 - accuracy: 0.9665 - mil_squared_error: 0.0647 - val_loss: 0.5292 - val_accuracy: 0.9167 - val_mil_squared_error: 0.0769\n",
      "Epoch 44/150\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.4863 - accuracy: 0.9665 - mil_squared_error: 0.0593 - val_loss: 0.5239 - val_accuracy: 0.9167 - val_mil_squared_error: 0.0736\n",
      "Epoch 45/150\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.4593 - accuracy: 0.9777 - mil_squared_error: 0.0484 - val_loss: 0.5184 - val_accuracy: 0.9167 - val_mil_squared_error: 0.0697\n",
      "Epoch 46/150\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.4759 - accuracy: 0.9553 - mil_squared_error: 0.0466 - val_loss: 0.5131 - val_accuracy: 0.9167 - val_mil_squared_error: 0.0665\n",
      "Epoch 47/150\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.4596 - accuracy: 0.9497 - mil_squared_error: 0.0399 - val_loss: 0.5076 - val_accuracy: 0.9167 - val_mil_squared_error: 0.0624\n",
      "Epoch 48/150\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.4611 - accuracy: 0.9330 - mil_squared_error: 0.0432 - val_loss: 0.5023 - val_accuracy: 0.9167 - val_mil_squared_error: 0.0604\n",
      "Epoch 49/150\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.4471 - accuracy: 0.9665 - mil_squared_error: 0.0458 - val_loss: 0.4967 - val_accuracy: 0.9167 - val_mil_squared_error: 0.0573\n",
      "Epoch 50/150\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.4444 - accuracy: 0.9609 - mil_squared_error: 0.0406 - val_loss: 0.4912 - val_accuracy: 0.9167 - val_mil_squared_error: 0.0550\n",
      "Epoch 51/150\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.4378 - accuracy: 0.9385 - mil_squared_error: 0.0383 - val_loss: 0.4858 - val_accuracy: 0.9333 - val_mil_squared_error: 0.0525\n",
      "Epoch 52/150\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.4265 - accuracy: 0.9665 - mil_squared_error: 0.0377 - val_loss: 0.4800 - val_accuracy: 0.9167 - val_mil_squared_error: 0.0488\n",
      "Epoch 53/150\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.4251 - accuracy: 0.9441 - mil_squared_error: 0.0333 - val_loss: 0.4745 - val_accuracy: 0.9333 - val_mil_squared_error: 0.0467\n",
      "Epoch 54/150\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.4023 - accuracy: 0.9665 - mil_squared_error: 0.0300 - val_loss: 0.4688 - val_accuracy: 0.9333 - val_mil_squared_error: 0.0442\n",
      "Epoch 55/150\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.4156 - accuracy: 0.9665 - mil_squared_error: 0.0280 - val_loss: 0.4630 - val_accuracy: 0.9333 - val_mil_squared_error: 0.0415\n",
      "Epoch 56/150\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.4095 - accuracy: 0.9665 - mil_squared_error: 0.0290 - val_loss: 0.4571 - val_accuracy: 0.9167 - val_mil_squared_error: 0.0379\n",
      "Epoch 57/150\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.3929 - accuracy: 0.9888 - mil_squared_error: 0.0238 - val_loss: 0.4515 - val_accuracy: 0.9167 - val_mil_squared_error: 0.0360\n",
      "Epoch 58/150\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.3860 - accuracy: 0.9721 - mil_squared_error: 0.0309 - val_loss: 0.4458 - val_accuracy: 0.9167 - val_mil_squared_error: 0.0340\n",
      "Epoch 59/150\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.3736 - accuracy: 0.9888 - mil_squared_error: 0.0161 - val_loss: 0.4400 - val_accuracy: 0.9167 - val_mil_squared_error: 0.0321\n",
      "Epoch 60/150\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.3780 - accuracy: 0.9777 - mil_squared_error: 0.0208 - val_loss: 0.4343 - val_accuracy: 0.9333 - val_mil_squared_error: 0.0304\n",
      "Epoch 61/150\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.3647 - accuracy: 0.9721 - mil_squared_error: 0.0229 - val_loss: 0.4285 - val_accuracy: 0.9167 - val_mil_squared_error: 0.0282\n",
      "Epoch 62/150\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.3541 - accuracy: 0.9609 - mil_squared_error: 0.0181 - val_loss: 0.4227 - val_accuracy: 0.9167 - val_mil_squared_error: 0.0258\n",
      "Epoch 63/150\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.3523 - accuracy: 0.9832 - mil_squared_error: 0.0175 - val_loss: 0.4171 - val_accuracy: 0.9167 - val_mil_squared_error: 0.0247\n",
      "Epoch 64/150\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.3510 - accuracy: 0.9832 - mil_squared_error: 0.0144 - val_loss: 0.4115 - val_accuracy: 0.9167 - val_mil_squared_error: 0.0220\n",
      "Epoch 65/150\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.3395 - accuracy: 0.9721 - mil_squared_error: 0.0121 - val_loss: 0.4058 - val_accuracy: 0.9333 - val_mil_squared_error: 0.0214\n",
      "Epoch 66/150\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.3230 - accuracy: 0.9832 - mil_squared_error: 0.0147 - val_loss: 0.4001 - val_accuracy: 0.9333 - val_mil_squared_error: 0.0200\n",
      "Epoch 67/150\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.3227 - accuracy: 0.9832 - mil_squared_error: 0.0100 - val_loss: 0.3945 - val_accuracy: 0.9333 - val_mil_squared_error: 0.0186\n",
      "Epoch 68/150\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.3239 - accuracy: 0.9888 - mil_squared_error: 0.0122 - val_loss: 0.3889 - val_accuracy: 0.9333 - val_mil_squared_error: 0.0181\n",
      "Epoch 69/150\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.3200 - accuracy: 0.9777 - mil_squared_error: 0.0085 - val_loss: 0.3833 - val_accuracy: 0.9333 - val_mil_squared_error: 0.0164\n",
      "Epoch 70/150\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.3260 - accuracy: 0.9665 - mil_squared_error: 0.0087 - val_loss: 0.3778 - val_accuracy: 0.9333 - val_mil_squared_error: 0.0145\n",
      "Epoch 71/150\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.3067 - accuracy: 0.9888 - mil_squared_error: 0.0087 - val_loss: 0.3723 - val_accuracy: 0.9333 - val_mil_squared_error: 0.0132\n",
      "Epoch 72/150\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.2928 - accuracy: 0.9777 - mil_squared_error: 0.0090 - val_loss: 0.3667 - val_accuracy: 0.9333 - val_mil_squared_error: 0.0124\n",
      "Epoch 73/150\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.2992 - accuracy: 0.9777 - mil_squared_error: 0.0065 - val_loss: 0.3611 - val_accuracy: 0.9333 - val_mil_squared_error: 0.0116\n",
      "Epoch 74/150\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.2843 - accuracy: 0.9777 - mil_squared_error: 0.0050 - val_loss: 0.3559 - val_accuracy: 0.9333 - val_mil_squared_error: 0.0103\n",
      "Epoch 75/150\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.2961 - accuracy: 0.9665 - mil_squared_error: 0.0063 - val_loss: 0.3503 - val_accuracy: 0.9333 - val_mil_squared_error: 0.0096\n",
      "Epoch 76/150\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.2820 - accuracy: 0.9777 - mil_squared_error: 0.0065 - val_loss: 0.3447 - val_accuracy: 0.9333 - val_mil_squared_error: 0.0093\n",
      "Epoch 77/150\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.2810 - accuracy: 0.9665 - mil_squared_error: 0.0058 - val_loss: 0.3393 - val_accuracy: 0.9500 - val_mil_squared_error: 0.0088\n",
      "Epoch 78/150\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.2674 - accuracy: 0.9832 - mil_squared_error: 0.0055 - val_loss: 0.3343 - val_accuracy: 0.9333 - val_mil_squared_error: 0.0078\n",
      "Epoch 79/150\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.2595 - accuracy: 0.9721 - mil_squared_error: 0.0033 - val_loss: 0.3290 - val_accuracy: 0.9500 - val_mil_squared_error: 0.0077\n",
      "Epoch 80/150\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.2510 - accuracy: 0.9888 - mil_squared_error: 0.0046 - val_loss: 0.3239 - val_accuracy: 0.9500 - val_mil_squared_error: 0.0074\n",
      "Epoch 81/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179/179 [==============================] - 1s 4ms/step - loss: 0.2479 - accuracy: 0.9888 - mil_squared_error: 0.0035 - val_loss: 0.3190 - val_accuracy: 0.9500 - val_mil_squared_error: 0.0067\n",
      "Epoch 82/150\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.2445 - accuracy: 0.9944 - mil_squared_error: 0.0033 - val_loss: 0.3145 - val_accuracy: 0.9333 - val_mil_squared_error: 0.0057\n",
      "Epoch 83/150\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.2240 - accuracy: 0.9944 - mil_squared_error: 0.0024 - val_loss: 0.3095 - val_accuracy: 0.9333 - val_mil_squared_error: 0.0054\n",
      "Epoch 84/150\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.2312 - accuracy: 0.9888 - mil_squared_error: 0.0021 - val_loss: 0.3044 - val_accuracy: 0.9500 - val_mil_squared_error: 0.0053\n",
      "Epoch 85/150\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.2292 - accuracy: 0.9721 - mil_squared_error: 0.0032 - val_loss: 0.2999 - val_accuracy: 0.9333 - val_mil_squared_error: 0.0048\n",
      "Epoch 86/150\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.2154 - accuracy: 0.9944 - mil_squared_error: 0.0028 - val_loss: 0.2952 - val_accuracy: 0.9500 - val_mil_squared_error: 0.0046\n",
      "Epoch 87/150\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.2166 - accuracy: 0.9777 - mil_squared_error: 0.0019 - val_loss: 0.2908 - val_accuracy: 0.9333 - val_mil_squared_error: 0.0042\n",
      "Epoch 88/150\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.2193 - accuracy: 0.9888 - mil_squared_error: 0.0027 - val_loss: 0.2862 - val_accuracy: 0.9333 - val_mil_squared_error: 0.0040\n",
      "Epoch 89/150\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.2044 - accuracy: 0.9944 - mil_squared_error: 0.0021 - val_loss: 0.2817 - val_accuracy: 0.9500 - val_mil_squared_error: 0.0038\n",
      "Epoch 90/150\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.2088 - accuracy: 0.9832 - mil_squared_error: 0.0016 - val_loss: 0.2773 - val_accuracy: 0.9500 - val_mil_squared_error: 0.0035\n",
      "Epoch 91/150\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.1971 - accuracy: 0.9944 - mil_squared_error: 0.0017 - val_loss: 0.2731 - val_accuracy: 0.9333 - val_mil_squared_error: 0.0032\n",
      "Epoch 92/150\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.1943 - accuracy: 0.9888 - mil_squared_error: 0.0015 - val_loss: 0.2687 - val_accuracy: 0.9500 - val_mil_squared_error: 0.0031\n",
      "Epoch 93/150\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.1888 - accuracy: 0.9888 - mil_squared_error: 0.0010 - val_loss: 0.2646 - val_accuracy: 0.9500 - val_mil_squared_error: 0.0028\n",
      "Epoch 94/150\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.1940 - accuracy: 0.9888 - mil_squared_error: 0.0013 - val_loss: 0.2609 - val_accuracy: 0.9333 - val_mil_squared_error: 0.0025\n",
      "Epoch 95/150\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.1843 - accuracy: 0.9944 - mil_squared_error: 0.0011 - val_loss: 0.2570 - val_accuracy: 0.9500 - val_mil_squared_error: 0.0023\n",
      "Epoch 96/150\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.1822 - accuracy: 0.9832 - mil_squared_error: 9.1252e-04 - val_loss: 0.2534 - val_accuracy: 0.9500 - val_mil_squared_error: 0.0021\n",
      "Epoch 97/150\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.1801 - accuracy: 0.9944 - mil_squared_error: 8.3257e-04 - val_loss: 0.2495 - val_accuracy: 0.9500 - val_mil_squared_error: 0.0019\n",
      "Epoch 98/150\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.1806 - accuracy: 0.9888 - mil_squared_error: 6.4209e-04 - val_loss: 0.2459 - val_accuracy: 0.9500 - val_mil_squared_error: 0.0018\n",
      "Epoch 99/150\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.1670 - accuracy: 0.9888 - mil_squared_error: 9.5843e-04 - val_loss: 0.2417 - val_accuracy: 0.9500 - val_mil_squared_error: 0.0017\n",
      "Epoch 100/150\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.1630 - accuracy: 0.9888 - mil_squared_error: 6.2770e-04 - val_loss: 0.2380 - val_accuracy: 0.9500 - val_mil_squared_error: 0.0016\n",
      "Epoch 101/150\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.1539 - accuracy: 0.9944 - mil_squared_error: 7.1039e-04 - val_loss: 0.2343 - val_accuracy: 0.9500 - val_mil_squared_error: 0.0015\n",
      "Epoch 102/150\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.1646 - accuracy: 0.9832 - mil_squared_error: 9.6992e-04 - val_loss: 0.2302 - val_accuracy: 0.9833 - val_mil_squared_error: 0.0016\n",
      "Epoch 103/150\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.1474 - accuracy: 0.9944 - mil_squared_error: 6.1207e-04 - val_loss: 0.2269 - val_accuracy: 0.9667 - val_mil_squared_error: 0.0014\n",
      "Epoch 104/150\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.1471 - accuracy: 1.0000 - mil_squared_error: 5.8895e-04 - val_loss: 0.2238 - val_accuracy: 0.9667 - val_mil_squared_error: 0.0013\n",
      "Epoch 105/150\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.1386 - accuracy: 0.9888 - mil_squared_error: 6.4806e-04 - val_loss: 0.2208 - val_accuracy: 0.9667 - val_mil_squared_error: 0.0011\n",
      "Epoch 106/150\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.1370 - accuracy: 0.9832 - mil_squared_error: 5.3040e-04 - val_loss: 0.2178 - val_accuracy: 0.9667 - val_mil_squared_error: 0.0010\n",
      "Epoch 107/150\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.1460 - accuracy: 0.9888 - mil_squared_error: 3.0079e-04 - val_loss: 0.2145 - val_accuracy: 0.9667 - val_mil_squared_error: 9.7213e-04\n",
      "Epoch 108/150\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.1398 - accuracy: 0.9944 - mil_squared_error: 4.6131e-04 - val_loss: 0.2115 - val_accuracy: 0.9667 - val_mil_squared_error: 8.9588e-04\n",
      "Epoch 109/150\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.1442 - accuracy: 0.9944 - mil_squared_error: 2.5297e-04 - val_loss: 0.2092 - val_accuracy: 0.9500 - val_mil_squared_error: 7.8341e-04\n",
      "Epoch 110/150\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.1324 - accuracy: 0.9944 - mil_squared_error: 2.3574e-04 - val_loss: 0.2063 - val_accuracy: 0.9500 - val_mil_squared_error: 7.2402e-04\n",
      "Epoch 111/150\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.1291 - accuracy: 0.9944 - mil_squared_error: 3.5347e-04 - val_loss: 0.2042 - val_accuracy: 0.9500 - val_mil_squared_error: 6.4178e-04\n",
      "Epoch 112/150\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.1324 - accuracy: 0.9888 - mil_squared_error: 3.4836e-04 - val_loss: 0.2002 - val_accuracy: 0.9667 - val_mil_squared_error: 6.4868e-04\n",
      "Epoch 113/150\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.1365 - accuracy: 0.9888 - mil_squared_error: 2.5842e-04 - val_loss: 0.1973 - val_accuracy: 0.9667 - val_mil_squared_error: 6.1254e-04\n",
      "Epoch 114/150\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.1252 - accuracy: 0.9944 - mil_squared_error: 2.3861e-04 - val_loss: 0.1936 - val_accuracy: 0.9667 - val_mil_squared_error: 6.3033e-04\n",
      "Epoch 115/150\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.1227 - accuracy: 0.9944 - mil_squared_error: 2.9308e-04 - val_loss: 0.1905 - val_accuracy: 1.0000 - val_mil_squared_error: 6.2592e-04\n",
      "Epoch 116/150\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.1166 - accuracy: 0.9944 - mil_squared_error: 1.4905e-04 - val_loss: 0.1877 - val_accuracy: 1.0000 - val_mil_squared_error: 5.9377e-04\n",
      "Epoch 117/150\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.1213 - accuracy: 0.9944 - mil_squared_error: 1.6404e-04 - val_loss: 0.1852 - val_accuracy: 1.0000 - val_mil_squared_error: 5.2513e-04\n",
      "Epoch 118/150\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.1166 - accuracy: 0.9944 - mil_squared_error: 2.8366e-04 - val_loss: 0.1830 - val_accuracy: 0.9667 - val_mil_squared_error: 4.6220e-04\n",
      "Epoch 119/150\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.1124 - accuracy: 0.9888 - mil_squared_error: 2.0316e-04 - val_loss: 0.1812 - val_accuracy: 0.9667 - val_mil_squared_error: 3.9994e-04\n",
      "Epoch 120/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179/179 [==============================] - 1s 4ms/step - loss: 0.1124 - accuracy: 0.9888 - mil_squared_error: 2.4038e-04 - val_loss: 0.1788 - val_accuracy: 0.9667 - val_mil_squared_error: 3.7049e-04\n",
      "Epoch 121/150\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.1080 - accuracy: 0.9944 - mil_squared_error: 1.3659e-04 - val_loss: 0.1757 - val_accuracy: 0.9667 - val_mil_squared_error: 3.6880e-04\n",
      "Epoch 122/150\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.1059 - accuracy: 0.9944 - mil_squared_error: 1.7521e-04 - val_loss: 0.1732 - val_accuracy: 0.9667 - val_mil_squared_error: 3.5219e-04\n",
      "Epoch 123/150\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.1037 - accuracy: 0.9888 - mil_squared_error: 2.3633e-04 - val_loss: 0.1712 - val_accuracy: 0.9667 - val_mil_squared_error: 3.1829e-04\n",
      "Epoch 124/150\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.1058 - accuracy: 0.9944 - mil_squared_error: 1.5575e-04 - val_loss: 0.1691 - val_accuracy: 0.9667 - val_mil_squared_error: 2.9083e-04\n",
      "Epoch 125/150\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.0935 - accuracy: 0.9944 - mil_squared_error: 1.3048e-04 - val_loss: 0.1670 - val_accuracy: 0.9667 - val_mil_squared_error: 2.6910e-04\n",
      "Epoch 126/150\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.1061 - accuracy: 0.9944 - mil_squared_error: 6.5668e-05 - val_loss: 0.1636 - val_accuracy: 1.0000 - val_mil_squared_error: 2.8535e-04\n",
      "Epoch 127/150\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.0995 - accuracy: 0.9944 - mil_squared_error: 1.3460e-04 - val_loss: 0.1616 - val_accuracy: 1.0000 - val_mil_squared_error: 2.6282e-04\n",
      "Epoch 128/150\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.0893 - accuracy: 0.9944 - mil_squared_error: 1.4059e-04 - val_loss: 0.1603 - val_accuracy: 0.9667 - val_mil_squared_error: 2.2528e-04\n",
      "Epoch 129/150\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.0884 - accuracy: 0.9944 - mil_squared_error: 4.4092e-05 - val_loss: 0.1592 - val_accuracy: 0.9667 - val_mil_squared_error: 1.9714e-04\n",
      "Epoch 130/150\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.0953 - accuracy: 0.9944 - mil_squared_error: 8.5136e-05 - val_loss: 0.1572 - val_accuracy: 0.9667 - val_mil_squared_error: 1.8388e-04\n",
      "Epoch 131/150\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.0904 - accuracy: 0.9944 - mil_squared_error: 6.0963e-05 - val_loss: 0.1544 - val_accuracy: 0.9667 - val_mil_squared_error: 1.8445e-04\n",
      "Epoch 132/150\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.0846 - accuracy: 0.9944 - mil_squared_error: 1.0508e-04 - val_loss: 0.1516 - val_accuracy: 1.0000 - val_mil_squared_error: 1.9108e-04\n",
      "Epoch 133/150\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.0794 - accuracy: 0.9944 - mil_squared_error: 7.2609e-05 - val_loss: 0.1492 - val_accuracy: 1.0000 - val_mil_squared_error: 1.9214e-04\n",
      "Epoch 134/150\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.0828 - accuracy: 0.9888 - mil_squared_error: 5.7281e-05 - val_loss: 0.1479 - val_accuracy: 0.9833 - val_mil_squared_error: 1.6641e-04\n",
      "Epoch 135/150\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.0783 - accuracy: 0.9944 - mil_squared_error: 5.4237e-05 - val_loss: 0.1470 - val_accuracy: 0.9667 - val_mil_squared_error: 1.4352e-04\n",
      "Epoch 136/150\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.0802 - accuracy: 0.9944 - mil_squared_error: 4.6758e-05 - val_loss: 0.1457 - val_accuracy: 0.9667 - val_mil_squared_error: 1.3084e-04\n",
      "Epoch 137/150\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.0788 - accuracy: 1.0000 - mil_squared_error: 3.8941e-05 - val_loss: 0.1438 - val_accuracy: 0.9667 - val_mil_squared_error: 1.2440e-04\n",
      "Epoch 138/150\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.0759 - accuracy: 1.0000 - mil_squared_error: 2.9709e-05 - val_loss: 0.1415 - val_accuracy: 0.9833 - val_mil_squared_error: 1.2231e-04\n",
      "Epoch 139/150\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.0750 - accuracy: 0.9944 - mil_squared_error: 4.8731e-05 - val_loss: 0.1395 - val_accuracy: 0.9833 - val_mil_squared_error: 1.1920e-04\n",
      "Epoch 140/150\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.0801 - accuracy: 0.9944 - mil_squared_error: 3.6340e-05 - val_loss: 0.1371 - val_accuracy: 1.0000 - val_mil_squared_error: 1.2235e-04\n",
      "Epoch 141/150\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.0744 - accuracy: 0.9944 - mil_squared_error: 3.7276e-05 - val_loss: 0.1352 - val_accuracy: 1.0000 - val_mil_squared_error: 1.2143e-04\n",
      "Epoch 142/150\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.0733 - accuracy: 0.9944 - mil_squared_error: 3.9242e-05 - val_loss: 0.1339 - val_accuracy: 1.0000 - val_mil_squared_error: 1.0804e-04\n",
      "Epoch 143/150\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.0677 - accuracy: 0.9944 - mil_squared_error: 3.1497e-05 - val_loss: 0.1323 - val_accuracy: 1.0000 - val_mil_squared_error: 1.0090e-04\n",
      "Epoch 144/150\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.0641 - accuracy: 0.9944 - mil_squared_error: 3.5701e-05 - val_loss: 0.1312 - val_accuracy: 0.9833 - val_mil_squared_error: 9.0492e-05\n",
      "Epoch 145/150\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.0658 - accuracy: 1.0000 - mil_squared_error: 3.2743e-05 - val_loss: 0.1307 - val_accuracy: 0.9833 - val_mil_squared_error: 7.7993e-05\n",
      "Epoch 146/150\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.0686 - accuracy: 0.9944 - mil_squared_error: 2.5559e-05 - val_loss: 0.1296 - val_accuracy: 0.9833 - val_mil_squared_error: 7.1385e-05\n",
      "Epoch 147/150\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.0608 - accuracy: 1.0000 - mil_squared_error: 2.3801e-05 - val_loss: 0.1281 - val_accuracy: 0.9833 - val_mil_squared_error: 6.7700e-05\n",
      "Epoch 148/150\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.0737 - accuracy: 0.9888 - mil_squared_error: 2.1273e-05 - val_loss: 0.1264 - val_accuracy: 0.9833 - val_mil_squared_error: 6.5165e-05\n",
      "Epoch 149/150\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.0605 - accuracy: 0.9944 - mil_squared_error: 1.9410e-05 - val_loss: 0.1244 - val_accuracy: 0.9833 - val_mil_squared_error: 6.4906e-05\n",
      "Epoch 150/150\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.0612 - accuracy: 0.9944 - mil_squared_error: 1.7285e-05 - val_loss: 0.1232 - val_accuracy: 0.9833 - val_mil_squared_error: 6.0750e-05\n",
      "0.9745762711864406\n",
      "intermediate model summary: \n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1_input (InputLayer)  (None, 48, 272)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 24, 1500)          817500    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 12, 1500)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 12, 1500)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 6, 500)            1500500   \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 3, 500)            0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 3, 500)            0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1500)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               384256    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "=================================================================\n",
      "Total params: 2,702,256\n",
      "Trainable params: 2,702,256\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "full model summary: \n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 24, 1500)          817500    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 12, 1500)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 12, 1500)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 6, 500)            1500500   \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 3, 500)            0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 3, 500)            0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1500)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               384256    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 514       \n",
      "=================================================================\n",
      "Total params: 2,702,770\n",
      "Trainable params: 2,702,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = train_cnn()\n",
    "try:\n",
    "    del intermediate_layer_model\n",
    "except:\n",
    "    pass\n",
    "\n",
    "intermediate_layer_model = keras.Model(inputs=model.input,\n",
    "                                    outputs=model.get_layer(index=len(model.layers)-2).output)\n",
    "print('intermediate model summary: ')\n",
    "intermediate_layer_model.summary()\n",
    "intermediate_layer_model.save('..//models//intermediate_layer_model_cnn.hdf5')\n",
    "\n",
    "print('full model summary: ')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emp_miu_class_0 = 4.362856\n",
      "emp_miu_class_1 = 4.6469145\n"
     ]
    }
   ],
   "source": [
    "def get_emp_miu(X, y):\n",
    "    outputs = intermediate_layer_model.predict(X)\n",
    "    norms = [np.linalg.norm(output) for output in outputs]\n",
    "    emp_miu = np.mean(norms)\n",
    "    \n",
    "    path = '..//models//emp_miu_class_' + str(y) + '.npy'\n",
    "    print('emp_miu_class_' + str(y) + ' = ' + str(emp_miu))\n",
    "    np.save(path, emp_miu)\n",
    "    return emp_miu\n",
    "\n",
    "emp_miu_caregiver = get_emp_miu(X_caregiver, 0)\n",
    "emp_miu_patient = get_emp_miu(X_patient, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the emprical covar matrix is ()\n"
     ]
    }
   ],
   "source": [
    "def get_emp_sigma(emp_miu_0, emp_miu_1, X_0, X_1):\n",
    "\n",
    "    X_0 = intermediate_layer_model.predict(X_0)\n",
    "    X_1 = intermediate_layer_model.predict(X_1)\n",
    "\n",
    "    X_0_norms = [np.linalg.norm(x) for x in X_0]\n",
    "    X_1_norms = [np.linalg.norm(x) for x in X_1]\n",
    "\n",
    "    class_0 = [ (x-emp_miu_0) * (x-emp_miu_0) for x in X_0_norms] # should be transpose if not just a num\n",
    "    class_1 = [ (x-emp_miu_1) * (x-emp_miu_1) for x in X_1_norms]\n",
    "    emp_sigma = np.sum(class_0 + class_1)/(len(class_0) + len(class_1))\n",
    "    \n",
    "    '''\n",
    "    class_0 = [ (x-emp_miu_0) @ np.transpose(x-emp_miu_0) for x in intermediate_layer_model.predict(X_0) ]\n",
    "    class_1 = [ (x-emp_miu_1) @ np.transpose(x-emp_miu_1) for x in intermediate_layer_model.predict(X_1) ]\n",
    "\n",
    "    emp_sigma = (class_0 + class_1)/(len(class_0) + len(class_1))\n",
    "    '''\n",
    "\n",
    "    print('the emprical covar matrix is ' + str(emp_sigma.shape))\n",
    "\n",
    "    path = '..//models//inv_emp_sigma.npy'\n",
    "\n",
    "    try:\n",
    "        result = np.linalg.pinv(emp_sigma)\n",
    "    except:\n",
    "        result = emp_sigma\n",
    "\n",
    "    np.save(path, result)\n",
    "    return emp_sigma\n",
    "\n",
    "emp_sigma = get_emp_sigma(emp_miu_caregiver, emp_miu_patient, X_caregiver, X_patient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_emp_mahalanobis(X, y):\n",
    "    mahalanobis_coeff = 0\n",
    "\n",
    "    emp_miu = np.load('..//models//emp_miu_class_' + str(y) + '.npy')\n",
    "    inv_emp_sigma = np.load('..//models//inv_emp_sigma.npy')\n",
    "\n",
    "    try:\n",
    "        mahalanobis_dists = [np.linalg.norm(np.transpose(x-emp_miu) @ inv_emp_sigma @ (x-emp_miu)) for x in intermediate_layer_model.predict(X)]\n",
    "    except:\n",
    "        mahalanobis_dists = [np.linalg.norm((x-emp_miu) * inv_emp_sigma * (x-emp_miu)) for x in intermediate_layer_model.predict(X)]\n",
    "\n",
    "    mahalanobis_mean = np.mean(mahalanobis_dists)\n",
    "    mahalanobis_std = np.std(mahalanobis_dists)\n",
    "\n",
    "    print('mahalanobis mean for class ' + str(y) + ' is ' + str(mahalanobis_mean))\n",
    "    print('mahalanobis std for class ' + str(y) + ' is ' + str(mahalanobis_std))\n",
    "\n",
    "    np.save('..//models//mahalanobis_mean_class_' + str(y) + '.npy', mahalanobis_mean)\n",
    "    np.save('..//models//mahalanobis_std_class_' + str(y) + '.npy', mahalanobis_std)\n",
    "    \n",
    "    # np.linspace(0, 200, 2000, endpoint=False)\n",
    "    for coeff in np.linspace(0, 100, 100000, endpoint=False):\n",
    "        upper = mahalanobis_mean + coeff*mahalanobis_std\n",
    "        lower = mahalanobis_mean - coeff*mahalanobis_std\n",
    "        \n",
    "        valid_xs = []\n",
    "        for x in mahalanobis_dists:            \n",
    "            if lower < x and x < upper:\n",
    "                valid_xs.append(x)\n",
    "\n",
    "        if len(valid_xs)/len(X) > 0.75:\n",
    "            print(len(valid_xs)/len(X))\n",
    "            mahalanobis_coeff = coeff\n",
    "            np.save('..//models//mahalanobis_threshold_coefficient_class_' + str(y) + '.npy', coeff)\n",
    "            print('the mahalanobis threshold coefficient for class ' + str(y) + ' is ' + str(coeff))\n",
    "            break\n",
    "\n",
    "    return mahalanobis_mean, mahalanobis_std, mahalanobis_coeff\n",
    "\n",
    "\n",
    "#emp_sigma = get_emp_sigma(emp_miu_caregiver, emp_miu_patient, X_caregiver, X_patient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mahalanobis mean for class 0 is 24.455559\n",
      "mahalanobis std for class 0 is 0.076576635\n",
      "0.751412429378531\n",
      "the mahalanobis threshold coefficient for class 0 is 1.172\n",
      "mahalanobis mean for class 1 is 27.875002\n",
      "mahalanobis std for class 1 is 0.063289374\n",
      "0.7555555555555555\n",
      "the mahalanobis threshold coefficient for class 1 is 1.1380000000000001\n"
     ]
    }
   ],
   "source": [
    "m_mean_0, m_std_0, m_coeff_0 = get_emp_mahalanobis(X_caregiver, 0)\n",
    "m_mean_1, m_std_1, m_coeff_1 = get_emp_mahalanobis(X_patient, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_emp_miu(y):\n",
    "    path = 'models//emp_miu_class_' + str(y) + '.npy'\n",
    "    return np.load(path)\n",
    "\n",
    "def load_inv_emp_covar():\n",
    "    path = 'models//inv_emp_sigma.npy'\n",
    "    return np.load(path)\n",
    "\n",
    "def load_mahalanobis_mean(y):\n",
    "    path = 'models//mahalanobis_mean_class_' + str(y) + '.npy'\n",
    "    return np.load(path)\n",
    "\n",
    "def load_mahalanobis_std(y):\n",
    "    path = 'models//mahalanobis_std_class_' + str(y) + '.npy'\n",
    "    return np.load(path)\n",
    "\n",
    "def load_mahalanobis_coeff(y):\n",
    "    path = 'models//mahalanobis_threshold_class_' + str(y) + '.npy'\n",
    "    return np.load(path)\n",
    "\n",
    "def detect_ood(x, predicted_y):\n",
    "    \n",
    "    assert(predicted_y == '0' or predicted_y == '1')\n",
    "       \n",
    "    emp_miu = load_emp_miu(y)\n",
    "    inv_emp_sigma = load_inv_emp_covar()\n",
    "    m_mean = load_mahalanobis_mean(y)\n",
    "    m_std = load_mahalanobis_std(y)\n",
    "    coeff = load_mahalanobis_coeff(y)\n",
    "    \n",
    "    upper = m_mean + coeff*m_std\n",
    "    lower = m_mean - coeff*m_std\n",
    "\n",
    "    try:\n",
    "        m_dist = np.transpose(x-emp_miu) @ inv_emp_sigma @ (x-emp_miu)\n",
    "    except:\n",
    "        m = (x-emp_miu) * inv_emp_sigma * (x-emp_miu)\n",
    "    \n",
    "    if lower < m and m < upper:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('base': conda)",
   "language": "python",
   "name": "python37464bitbaseconda520b236a9c6d486bbc01b80a136b32a1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
